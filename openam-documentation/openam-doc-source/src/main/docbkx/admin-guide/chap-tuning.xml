<?xml version="1.0" encoding="UTF-8"?>
<!--
  ! CCPL HEADER START
  !
  ! This work is licensed under the Creative Commons
  ! Attribution-NonCommercial-NoDerivs 3.0 Unported License.
  ! To view a copy of this license, visit
  ! http://creativecommons.org/licenses/by-nc-nd/3.0/
  ! or send a letter to Creative Commons, 444 Castro Street,
  ! Suite 900, Mountain View, California, 94041, USA.
  !
  ! You can also obtain a copy of the license at
  ! src/main/resources/legal-notices/CC-BY-NC-ND.txt.
  ! See the License for the specific language governing permissions
  ! and limitations under the License.
  !
  ! If applicable, add the following below this CCPL HEADER, with the fields
  ! enclosed by brackets "[]" replaced with your own identifying information:
  !      Portions Copyright [yyyy] [name of copyright owner]
  !
  ! CCPL HEADER END
  !
  !      Copyright 2011-2014 ForgeRock, Inc
  !    
-->
<chapter xml:id='chap-tuning'
         xmlns='http://docbook.org/ns/docbook'
         version='5.0' xml:lang='en'
         xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
         xsi:schemaLocation='http://docbook.org/ns/docbook
                             http://docbook.org/xml/5.0/xsd/docbook.xsd'>
 <title>Tuning OpenAM</title>
 <indexterm><primary>Performance</primary></indexterm>
 <para>This chapter covers key OpenAM tunings to ensure smoothly performing
 access and federation management services, and to maximize throughput while
 minimizing response times.</para>
 
 <note>
  <para>The recommendations provided here are guidelines for your testing
  rather than hard and fast rules for every situation. Said another way, the
  fact that a given setting is configurable implies that no one setting is
  right in all circumstances.</para>

  <para>The extent to which performance tuning advice applies depends to a large
  extent on your requirements, on your workload, and on what resources you have
  available. Test suggestions before rolling them out into production.</para>
 </note>
 
 <para>As a rule of thumb, an OpenAM server in production with a 3 GB heap can
 handle 100,000 sessions. Although you might be tempted to use a larger heap
 with a 64-bit JVM, smaller heaps are easier to manage. Thus, rather than
 scaling single servers up to increase the total number of simultaneous
 sessions, consider scaling out by adding more servers instead. The suggestions
 that follow pertain to production servers.</para>
 
 <!-- The following is lifted from the OpenAM wiki work done by Steve Ferris,
 https://wikis.forgerock.org/confluence/display/openam/OpenAM+Performance+Tuning+Guide
      That page also includes container-specific advice for Apache HTTPD
      and Apache Tomcat used together. -->
 
 <section xml:id="tuning-openam-server">
  <title>OpenAM Server Settings</title>
  
  <para>OpenAM has a number of settings that can be tuned to increase
  performance.</para>
  
  <section xml:id="tuning-general-settings">
   <title>General Settings</title>
   <para>The following general points apply.</para>
   <itemizedlist>
    <listitem>
     <para>Set debug level to <literal>error</literal>.</para>
    </listitem>
    <listitem>
     <para>Disable session failover debugging.</para>
    </listitem>
    <listitem>
     <para>Set container-level logging to a low level such as
     <literal>error</literal> or <literal>severe</literal>.</para>
    </listitem>
   </itemizedlist>
  </section>
  
  <section xml:id="tuning-ldap-settings">
   <title>LDAP Settings</title>
   
   <para>
    Tune your LDAP data stores, your LDAP authentication modules,
    and connection pools for CTS and configuration stores.
   </para>

   <section xml:id="tuning-ldap-settings-data-stores">
    <title>Tuning LDAP Data Store Settings</title>

    <para>To change LDAP data store settings, browse to Access Control &gt;
    <replaceable>Realm Name</replaceable> &gt; Data Stores &gt;
    <replaceable>Data Store Name</replaceable> in the OpenAM console.
    Each data store has its own connection pool and therefore each data store
    needs its own tuning.</para>

    <table xml:id="tuning-ldap-data-store-settings" pgwide="1">
     <title>LDAP Data Store Settings</title>
     <tgroup cols="3">
      <colspec colnum="1" colwidth="2*"/>
      <colspec colnum="2" colwidth="1*"/>
      <colspec colnum="3" colwidth="3*"/>
      <thead>
       <row>
        <entry>Property</entry>
        <entry>Default Value</entry>
        <entry>Suggestions</entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>LDAP Connection Pool Minimum Size</entry>
        <entry>1</entry>
        <entry>
         <para>The minimum LDAP connection pool size; a good tuning value
         for this property is 10.</para>
         <para>(<literal>sun-idrepo-ldapv3-config-connection_pool_min_size</literal>)</para>
        </entry>
       </row>
       <row>
        <entry>LDAP Connection Pool Maximum Size</entry>
        <entry>10</entry>
        <entry>
         <para>The maximum LDAP connection pool size; a high tuning value
         for this property is 65, though you might well be able to reduce this
         for your deployment. Ensure your LDAP server can cope with the maximum
         number of clients across all the OpenAM servers.</para>
         <para>(<literal>sun-idrepo-ldapv3-config-connection_pool_max_size</literal>)</para>
        </entry>
       </row>
          <!-- no longer included in the console
       <row>
        <entry>Caching</entry>
        <entry>False</entry>
        <entry>
         <para>Turn on the caching feature in the LDAP data store.</para>
         <para>(<literal>sun-idrepo-ldapv3-config-cache-enabled</literal>)</para>
        </entry>
       </row>
       <row>
        <entry>Maximum Age of Cached Items</entry>
        <entry>600</entry>
        <entry>
         <para>This is 10 minutes and does not normally need tuning.</para>
         <para>(<literal>sun-idrepo-ldapv3-config-cache-ttl</literal>)</para>
        </entry>
       </row>
       <row>
        <entry>Maximum Size of the Cache</entry>
        <entry>10240</entry>
        <entry>
         <para>This is 10k and is very small for a cache. A 1 MB cache (1048576)
         is a better starting point.</para>
         <para>(<literal>sun-idrepo-ldapv3-config-cache-size</literal>)</para>
        </entry>
       </row>
       -->
      </tbody>
     </tgroup>
    </table>
   </section>

   <section xml:id="tuning-ldap-settings-auth-modules">
    <title>Tuning LDAP Authentication Module Settings</title>

    <para>To change connection pool settings for the LDAP authentication module,
    browse to Configuration &gt; Authentication &gt; Core in the OpenAM
    console.</para>

    <table xml:id="tuning-ldap-authentication-module-settings" pgwide="1">
     <title>LDAP Authentication Module Setting</title>
     <tgroup cols="3">
      <colspec colnum="1" colwidth="2*"/>
      <colspec colnum="2" colwidth="1*"/>
      <colspec colnum="3" colwidth="3*"/>
      <thead>
       <row>
        <entry>Property</entry>
        <entry>Default Value</entry>
        <entry>Suggestions</entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>Default LDAP Connection Pool Size</entry>
        <entry>1:10</entry>
        <entry>
         <para>The minimum and maximum LDAP connection pool used by the
         LDAP authentication module. This should be tuned to 10:65 for
         production.</para>
         <para>(<literal>iplanet-am-auth-ldap-connection-pool-default-size</literal>)</para>
        </entry>
       </row>
      </tbody>
     </tgroup>
    </table>
   </section>

   <section xml:id="tuning-ldap-settings-cts">
    <title>Tuning LDAP CTS &amp; Configuration Store Settings</title>

    <para>
     When tuning LDAP connection pool settings for the Core Token Service (CTS),
     what you change depends on whether the directory service backing the CTS
     is the same directory service backing OpenAM configuration.
    </para>

    <para>
     When the same directory service backs
     both the CTS and also OpenAM configuration (the default),
     then the same connection pool is shared for any LDAP operations requested
     by the CTS or by a service accessing the OpenAM configuration.
     In this case, one connection is reserved for cleanup of expired CTS tokens.
     Roughly half of the connections are allocated for CTS operations,
     to the nearest power of two.<footnote>
      <para>
       To be precise, the number of connections allocated for CTS operations
       is equal to the power of two that is nearest to
       half the maximum number of connections in the pool.
      </para>
     </footnote>
     The remaining connections are allocated
     to services accessing the OpenAM configuration.
     For a default configuration,
     where the maximum number of connections in the pool is 10,
     1 connection is allocated for cleanup of expired CTS tokens,
     4 connections are allocated for other CTS operations,
     and 5 connections are allocated for services accessing the configuration.
     If the Maximum Connection Pool size is 20,
     1 connection is allocated for cleanup of expired CTS tokens,
     8 connections are allocated for other CTS operations,
     and 11 connections are allocated for services accessing the configuration.
     If the pool size is 65, then the numbers are 1, 32, and 32, and so on.
    </para>

    <para>
     The minimum number of connections is 6.
    </para>

    <para>
     When the directory service backing the CTS is external
     (differs from the directory service backing the OpenAM configuration)
     then the connection pool used to access the directory service for the CTS
     is separate from the pool used to access the directory service
     for the OpenAM configuration.
     One connection is reserved for cleanup of expired CTS tokens.
     Remaining connections are allocated for CTS operations
     such that the number of connections allocated is equal to a power of two.
     In this case, set the maximum number of connections to 2^n+1,
     as in 9, 17, 33, 65, and so forth.
    </para>

    <para>
     If the same directory service backs
     both the CTS and also OpenAM configuration,
     then set pool sizes under
     Configuration > Servers and Sites > <replaceable>server name</replaceable>
     > Directory Configuration.
    </para>

    <para>
     If the directory service backing the CTS is external
     (differs from the directory service backing the OpenAM configuration),
     then set the maximum connection pool size under
     Configuration > Servers and Sites > <replaceable>server name</replaceable>
     > CTS > External Store Configuration.
    </para>

    <para>
     In both cases, if you must change the default connection timeouts,
     set the advanced properties described below under
     Configuration > Servers and Sites > <replaceable>server name</replaceable>
     > Advanced.
    </para>

    <table xml:id="tuning-ldap-cts-settings" pgwide="1">
     <title>CTS Store LDAP Connection Pool Settings</title>
     <tgroup cols="3">
      <colspec colnum="1" colwidth="2*"/>
      <colspec colnum="2" colwidth="1*"/>
      <colspec colnum="3" colwidth="3*"/>
      <thead>
       <row>
        <entry>Property</entry>
        <entry>Default Value</entry>
        <entry>Suggestions</entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>Maximum Connection Pool</entry>
        <entry>10</entry>
        <entry>
         <para>
          Find this setting in OpenAM console under
          Configuration > Servers and Sites > <replaceable>server name</replaceable>
          > Directory Configuration.
         </para>

         <!--
          Here is a guesstimate based on the pre-CTS default setting:
         -->

         <para>
          When the same directory service backs
          both the CTS and also OpenAM configuration,
          consider increasing this to at least 19
          to allow 9 connections for the CTS,
          and 10 connections for access to the OpenAM configuration
          (including for example looking up policies).
         </para>
        </entry>
       </row>

       <row>
        <entry>Max Connections</entry>
        <entry>10</entry>
        <entry>
         <para>
          Find this setting in OpenAM console under
          Configuration > Servers and Sites > <replaceable>server name</replaceable>
          > CTS > External Store Configuration.
         </para>

         <para>
          When the directory service backing the CTS is external
          and the load on the CTS is high,
          consider setting this to 2^n+1, where n = 4, 5, 6, and so on.
          In other words, try setting this to 17, 33, 65, and so on
          when testing performance under load.
         </para>

         <para>
          (<literal>org-forgerock-services-cts-store-max-connections</literal>)
         </para>
        </entry>
       </row>

       <row>
        <entry>CTS connection timeout (advanced property)</entry>
        <entry>10 (seconds)</entry>
        <entry>
         <para>
          Most CTS requests to the directory server are handled quickly,
          so the default timeout is fine for most cases.
         </para>

         <para>
          If you choose to vary this setting for performance testing,
          set the advanced property,
          <literal>org.forgerock.services.datalayer.connection.timeout.cts.async</literal>,
          under Configuration > Servers and Sites > <replaceable>server name</replaceable>
          > Advanced.
         </para>

         <para>
          You must restart OpenAM or the container in which it runs
          for changes to take effect.
         </para>
        </entry>
       </row>

       <row>
        <entry>CTS reaper timeout (advanced property)</entry>
        <entry>None</entry>
        <entry>
         <para>
          The CTS token cleanup connection generally should not time out
          as it is used to request long-running queries
          that can return many results.
         </para>

         <para>
          If you choose to vary this setting for performance testing,
          set the advanced property,
          <literal>org.forgerock.services.datalayer.connection.timeout.cts.reaper</literal>,
          to the number of seconds desired
          under Configuration > Servers and Sites > <replaceable>server name</replaceable>
          > Advanced.
         </para>

         <para>
          You must restart OpenAM or the container in which it runs
          for changes to take effect.
         </para>
        </entry>
       </row>

       <row>
        <entry>Configuration management connection timeout (advanced property)</entry>
        <entry>10 (seconds)</entry>
        <entry>
         <para>
          Most configuration management requests to the directory server
          are handled quickly, so the default timeout is fine for most cases.
         </para>

         <para>
          If you choose to vary this setting for performance testing,
          set the advanced property,
          <literal>org.forgerock.services.datalayer.connection.timeout</literal>,
          under Configuration > Servers and Sites > <replaceable>server name</replaceable>
          > Advanced.
         </para>

         <para>
          You must restart OpenAM or the container in which it runs
          for changes to take effect.
         </para>
        </entry>
       </row>
      </tbody>
     </tgroup>
    </table>
   </section>
  </section>

  <section xml:id="tuning-notification-settings">
   <title>Notification Settings</title>
   
   <para>OpenAM has two thread pools used to send notifications to clients. The
   Service Management Service thread pool can be tuned in OpenAM console under
   Configuration &gt; Servers and Sites &gt; Default Server Settings &gt;
   SDK.</para>
   
   <table xml:id="tuning-sms-notifications" pgwide="1">
    <title>SMS Notification Setting</title>
    <tgroup cols="3">
     <colspec colnum="1" colwidth="2*"/>
     <colspec colnum="2" colwidth="1*"/>
     <colspec colnum="3" colwidth="3*"/>
     <thead>
      <row>
       <entry>Property</entry>
       <entry>Default Value</entry>
       <entry>Suggestions</entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>Notification Pool Size</entry>
       <entry>10</entry>
       <entry>
        <para>This is the size of the thread pool used to send notifications.
        In production this value should be fine unless lots of
        clients are registering for SMS notifications.</para>
        <para>(<literal>com.sun.identity.sm.notification.threadpool.size</literal>)</para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
   
   <para>The session service has its own thread pool to send notifications.
   This is configured under Configuration &gt; Servers and Sites &gt; Default
   Server Settings &gt; Session.</para>
   
   <table xml:id="tuning-session-service-notifications" pgwide="1">
    <title>Session Service Notification Settings</title>
    <tgroup cols="3">
     <colspec colnum="1" colwidth="2*"/>
     <colspec colnum="2" colwidth="1*"/>
     <colspec colnum="3" colwidth="3*"/>
     <thead>
      <row>
       <entry>Property</entry>
       <entry>Default Value</entry>
       <entry>Suggestions</entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>Notification Pool Size</entry>
       <entry>10</entry>
       <entry>
        <para>This is the size of the thread pool used to send notifications.
        In production this should be around 25-30.</para>
        <para>(<literal>com.iplanet.am.notification.threadpool.size</literal>)</para>
       </entry>
      </row>
      <row>
       <entry>Notification Thread Pool Threshold</entry>
       <entry>5000</entry>
       <entry>
        <para>This is the maximum number of notifications in the queue waiting
        to be sent. The default value should be fine in the majority of
        installations.</para>
        <para>(<literal>com.iplanet.am.notification.threadpool.threshold</literal>)</para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </section>
  
  <section xml:id="tuning-session-settings">
   <title>Session Settings</title>
  
   <para>The session service has additional properties to tune, which are
   configured under Configuration &gt; Servers and Sites &gt; Default
   Server Settings &gt; Session.</para>
   
   <table xml:id="tuning-session-service-settings" pgwide="1">
    <title>Session Settings</title>
    <tgroup cols="3">
     <colspec colnum="1" colwidth="2*"/>
     <colspec colnum="2" colwidth="1*"/>
     <colspec colnum="3" colwidth="3*"/>
     <thead>
      <row>
       <entry>Property</entry>
       <entry>Default Value</entry>
       <entry>Suggestions</entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>Maximum Sessions</entry>
       <entry>5000</entry>
       <entry>
        <para>In production this value can safely be set into the 100,000s.
        The maximum session limit is really controlled by the maximum size of
        the JVM heap which must be tuned appropriately to match the expected
        number of concurrent sessions.</para>
        <para>(<literal>com.iplanet.am.session.maxSessions</literal>)</para>
       </entry>
      </row>
      <row>
       <entry>Sessions Purge Delay</entry>
       <entry>0</entry>
       <entry>
        <para>This should be zero to ensure sessions are purged immediately.</para>
        <para>(<literal>com.iplanet.am.session.purgedelay</literal>)</para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </section>
 </section>
 
 <section xml:id="tuning-jvm-for-openam">
  <title>Java Virtual Machine Settings</title>
  
  <para>This section gives some initial guidance on configuring the JVM for
  running OpenAM. These settings provide a strong foundation to the JVM before
  a more detailed garbage collection tuning exercise, or as best practice
  configuration for production.</para>
  
  <table xml:id="tuning-heap-size" pgwide="1">
   <title>Heap Size Settings</title>
   <tgroup cols="3">
    <colspec colnum="1" colwidth="3*"/>
    <colspec colnum="2" colwidth="2*"/>
    <colspec colnum="3" colwidth="2*"/>
    <thead>
     <row>
      <entry>JVM Parameters</entry>
      <entry>Suggested Value</entry>
      <entry>Description</entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry><para><literal>-Xms</literal> &amp;
      <literal>-Xmx</literal></para></entry>
      <entry><para>At least 1024m (2048m with embedded OpenDJ), in production
      environments at least 2048m to 3072m. This setting depends on the available
      physical memory, and on whether a 32 or 64-bit JVM is used.</para></entry>
      <entry><para>-</para></entry>
     </row>
     <row>
      <entry><para><literal>-server</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Ensures the server JVM is used</para></entry>
     </row>
<!--     <row>
      <entry><para><literal>-Xss</literal></para></entry>
      <entry><para>132k</para></entry>
      <entry><para>The stack size for each thread</para></entry>
     </row> -->
     <row>
      <entry><para><literal>-XX:PermSize</literal> &amp;
      <literal>-XX:MaxPermSize</literal></para></entry>
      <entry><para>Set both to 256m</para></entry>
      <entry><para>Controls the size of the permanent generation in the
      JVM</para></entry>
     </row>
     <row>
      <entry><para><literal>-Dsun.net.client.defaultReadTimeout</literal></para></entry>
      <entry><para>60000</para></entry>
      <entry><para>Controls the read timeout in the Java HTTP client
      implementation</para>
      <para>This applies only to the Sun/Oracle HotSpot JVM.</para></entry>
     </row>
     <row>
      <entry><para><literal>-Dsun.net.client.defaultConnectTimeout</literal></para></entry>
      <entry>High setting: <para>30000</para> (30 seconds)</entry>
      <entry><para>Controls the connect timeout in the Java HTTP client
      implementation</para>
      <para>When you have hundreds of incoming requests per second, reduce this
      value to avoid a huge connection queue.</para>
      <para>This applies only to the Sun/Oracle HotSpot JVM.</para></entry>
     </row>
    </tbody>
   </tgroup>
  </table>
  
  <table xml:id="tuning-garbage-collection" pgwide="1">
   <title>Garbage Collection Settings</title>
   <tgroup cols="3">
    <colspec colnum="1" colwidth="3*"/>
    <colspec colnum="2" colwidth="2*"/>
    <colspec colnum="3" colwidth="2*"/>
    <thead>
     <row>
      <entry>JVM Parameters</entry>
      <entry>Suggested Value</entry>
      <entry>Description</entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry><para><literal>-verbose:gc</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Verbose garbage collection reporting</para></entry>
     </row>
     <row>
      <entry><para><literal>-Xloggc:</literal></para></entry>
      <entry><para><filename>$CATALINA_HOME/logs/gc.log</filename></para></entry>
      <entry><para>Location of the verbose garbage collection log
      file</para></entry>
     </row>
     <row>
      <entry><para><literal>-XX:+PrintClassHistogram</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Prints a heap histogram when a SIGTERM signal is received
      by the JVM</para></entry>
     </row>
     <row>
      <entry><para><literal>-XX:+PrintGCDetails</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Prints detailed information about garbage collection</para></entry>
     </row>
     <row>
      <entry><para><literal>-XX:+PrintGCTimeStamps</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Prints detailed garbage collection timings</para></entry>
     </row>
     <row>
      <entry><para><literal>-XX:+HeapDumpOnOutOfMemoryError</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Out of Memory errors generate a heap dump
      automatically</para></entry>
     </row>
     <row>
      <entry><para><literal>-XX:HeapDumpPath</literal></para></entry>
      <entry><para><filename>$CATALINA_HOME/logs/heapdump.hprof</filename></para></entry>
      <entry><para>Location of the heap dump</para></entry>
     </row>
     <row>
      <entry><para><literal>-XX:+UseConcMarkSweepGC</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Use the concurrent mark sweep garbage collector</para></entry>
     </row>
     <row>
      <entry><para><literal>-XX:+UseCMSCompactAtFullCollection</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Aggressive compaction at full collection</para></entry>
     </row>
     <row>
      <entry><para><literal>-XX:+CMSClassUnloadingEnabled</literal></para></entry>
      <entry><para>-</para></entry>
      <entry><para>Allow class unloading during CMS sweeps</para></entry>
     </row>
    </tbody>
   </tgroup>
  </table>
 </section>

 <section xml:id="caching">
  <title>Caching in OpenAM</title>
  <indexterm><primary>Caching</primary></indexterm>

  <para>OpenAM caches data to avoid having to query user and configuration
  data stores each time it needs the information. By default, OpenAM makes use
  of LDAP persistent search to receive notification of changes to cached data.
  For this reason, caching works best when data are stored in a directory
  server that supports LDAP persistent search.</para>

  <para>OpenAM has two kinds of cache on the server side that you can configure,
  one for configuration data and the other for user data. Generally use the
  default settings for configuration data cache. This section mainly covers the
  configuration choices you have for caching user data.</para>

  <para>OpenAM implements the global user data cache for its user data
   stores.
   Prior to OpenAM 11.0, OpenAM supported a secondary Time-to-Live (TTL)
   data store caching layer, which has since been removed in OpenAM 11.0 and later
   versions.
  </para>

  <para>The user data store also supports a DN Cache, used to cache DN lookups
   that tend to occur in bursts during authentication.
   The DN Cache can become out of date when a user is moved or renamed in the
   underlying LDAP store, events that are not always reflected in a persistent search result.
   You can enable the DN cache when the underlying LDAP store supports persistent
   search and <literal>mod DN</literal> operations (that is, move or rename DN).</para>

  <para>The following diagram depicts the two kinds of cache, and also the
   two types of caching available for user data.</para>

  <mediaobject xml:id="figure-openam-caches">
   <alt>Caches in OpenAM server</alt>
   <imageobject>
    <imagedata fileref="images/openam-caches.png" format="PNG" />
   </imageobject>
   <textobject><para>OpenAM server caches user data and configuration data
   separately.</para></textobject>
  </mediaobject>

  <para>The rest of this section concerns mainly settings for global user data
  cache and for SDK clients. For a look at data store cache settings, see
  <xref linkend="tuning-ldap-data-store-settings" />.</para>

  <section xml:id="caching-server-settings">
   <title>Overall Server Cache Settings</title>

   <para>By default OpenAM has caching enabled both for configuration data and
   also for user data. This setting is governed by the server property
   <literal>com.iplanet.am.sdk.caching.enabled</literal>, which by default is
   <literal>true</literal>. When you set this advanced property to
   <literal>false</literal>, then you can enable caching independently for
   configuration data and for user data.</para>

   <procedure xml:id="turn-off-global-user-data-caching">
    <title>To Turn Off Global User Data Caching</title>

    <para><emphasis role="strong">Disabling caching can have a severe negative
    impact on performance. This is because, when caching is disabled, OpenAM
    must query a data store each time it needs data.</emphasis></para>

    <para>If, however, you have at least one user data store that does not
    support LDAP persistent search, such as a relational database or an LDAP
    directory server that does not support persistent search, then you must
    disable the <emphasis>global</emphasis> cache for user data. Otherwise user
    data caches cannot stay in sync with changes to user data entries.</para>

    <step>
     <para>In the OpenAM console, browse to Configuration &gt; Servers and Sites
     &gt; <replaceable>Server Name</replaceable> &gt; Advanced.</para>
    </step>

    <step>
     <para>Set <literal>com.iplanet.am.sdk.caching.enabled</literal> to
     <literal>false</literal> to disable caching overall.</para>
    </step>

    <step>
     <para>Set <literal>com.sun.identity.sm.cache.enabled</literal> to
     <literal>true</literal> to enable configuration data caching.</para>

     <para>All supported configuration data stores support LDAP persistent
     search, so it is safe to enable configuration data caching.</para>

     <para>You must explicitly set this property to <literal>true</literal>,
     because setting <literal>com.iplanet.am.sdk.caching.enabled</literal> to
     <literal>false</literal> in the previous step disables both user and
     configuration data caching.</para>
    </step>

    <step>
     <para>Save your work.</para>
    </step>
   </procedure>

   <procedure xml:id="change-max-cache-size">
    <title>To Change the Maximum Size of Global User Data Cache</title>

    <para>With a large user data store and active user base, the number of user
    entries in cache can grow large.</para>

    <step>
     <para>In the OpenAM console, browse to Configuration &gt; Servers and Sites
     &gt; Default Server Settings &gt; SDK.</para>
    </step>

    <step>
     <para>Change the value of SDK Caching Max. Size, and then Save your
     work.</para>

     <para>There is no corresponding setting for configuration data, as the
     number of configuration entries in a large deployment is not likely to
     grow nearly as large as the number of user entries.</para>
    </step>
   </procedure>
  </section>

  <section xml:id="java-ee-policy-agent-and-sdk-caching">
   <title>Caching Properties For Java EE Policy Agents &amp; SDK Clients</title>

   <para>Policy agents and other OpenAM SDK clients can also cache user data,
   using most of the same properties as OpenAM server as described in
   <xref linkend="table-cache-properties" /> . Clients however can receive
   updates by notification from OpenAM or, if notification fails, by
   polling OpenAM for changes.</para>

   <procedure xml:id="notify-sdk-cache-updates">
    <title>To Enable Notification &amp; Polling For Client Cache Updates</title>

    <para>This procedure describes how to enable change notification and polling
    for policy agent user data cache updates. When configuring a custom OpenAM
    SDK client using a .properties file, use the same properties as for the
    policy agent configuration.</para>

    <step>
     <para>In OpenAM console, browse to Access Control &gt; <replaceable>Realm
     Name</replaceable> &gt; Agents &gt; <replaceable>Agent Type</replaceable>
     &gt; <replaceable>Agent Name</replaceable> to view and edit the policy
     agent profile.</para>
    </step>

    <step>
     <para>On the Global tab page, check that the Agent Notification URL is
     set.</para>

     <para>When notification is enabled, the agent registers a notification
     listener with OpenAM for this URL.</para>

     <para>The corresponding property is
     <literal>com.sun.identity.client.notification.url</literal>.</para>
    </step>

  <!-- Options not shown

    <step>
     <para>On the OpenAM Services tab, check that Enable Notification of User
     Data Caches is enabled.</para>

     <para>The corresponding property is
     <literal>com.sun.identity.idm.remote.notification.enabled</literal>.</para>
    </step>

    <step>
     <para>On the OpenAM Services tab, check that User Data Cache Polling Time
     is set.</para>

     <para>This ensures that if notifications fail for some reason, the policy
     agent polls OpenAM for changes.</para>

     <para>The corresponding property is
     <literal>com.iplanet.am.sdk.remote.pollingTime</literal>.</para>
    </step>
                                                 -->
    <step>
     <para>For any changes you make, Save your work.</para>

     <para>You must restart the policy agent for the changes to take
     effect.</para>
    </step>
   </procedure>
  </section>

  <section xml:id="caching-properties">
   <title>Cache Settings</title>

   <para>The table below provides a quick reference, primarily for user data
   cache settings.</para>

   <para>Notice that many properties for configuration data cache have
   <literal>sm</literal> (for Service Management) in their names, whereas those
   for user data have <literal>idm</literal> (for Identity Management) in their
   names.</para>

   <table xml:id="table-cache-properties" pgwide="1">
    <title>OpenAM Cache Properties</title>
    <tgroup cols="4">
     <colspec colnum="1" colwidth="3*"/>
     <colspec colnum="2" colwidth="3*"/>
     <colspec colnum="3" colwidth="1*"/>
     <colspec colnum="4" colwidth="1*"/>
     <thead>
      <row>
       <entry>Property</entry>
       <entry>Description</entry>
       <entry>Default</entry>
       <entry>Applies To</entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry><para><literal>com.iplanet.am.sdk.cache.maxSize</literal></para></entry>
       <entry><para>Maximum number of user entries cached</para></entry>
       <entry><para>10000</para></entry>
       <entry><para>Server &amp; SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>com.iplanet.am.sdk.caching.enabled</literal></para></entry>
       <entry>
        <para>Whether to enable caching for both configuration data and also
        for user data.</para>

        <para>If <literal>true</literal>, this setting overrides
        <literal>com.sun.identity.idm.cache.enabled</literal> and
        <literal>com.sun.identity.sm.cache.enabled</literal>.</para>

        <para>If <literal>false</literal>, you can enable caching independently
        for configuration data and for user data using the aforementioned
        properties.</para>
       </entry>
       <entry><para><literal>true</literal></para></entry>
       <entry><para>Server &amp; SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>com.iplanet.am.sdk.remote.pollingTime</literal></para></entry>
       <entry>
        <para>How often in minutes the SDK client such as a policy agent should
        poll OpenAM for modified user data entries.</para>

        <para>The SDK also uses this value to determine the age of the oldest
        changes requested. The oldest changes requested are 2 minutes older than
        this setting. In other words, by default the SDK polls for entries
        changed in the last 3 minutes.</para>

        <para>Set this to 0 or a negative integer to disable polling.</para>
       </entry>
       <entry><para>1 (minute)</para></entry>
       <entry><para>SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>com.sun.am.event.notification.expire.time</literal></para></entry>
       <entry>
        <para>How long OpenAM stores a given change to a cached entry, so that
        clients polling for changes do not miss the change.</para>
       </entry>
       <entry><para>30 (minutes)</para></entry>
       <entry><para>Server only</para></entry>
      </row>

      <row>
       <entry><para><literal>com.sun.identity.idm.cache.enabled</literal></para></entry>
       <entry>
        <para>If <literal>com.iplanet.am.sdk.caching.enabled</literal> is
        <literal>true</literal>, this property is ignored.</para>

        <para>Otherwise, set this to <literal>true</literal> to enable caching
        of user data.</para>
       </entry>
       <entry><para><literal>false</literal></para></entry>
       <entry><para>Server &amp; SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>com.sun.identity.idm.cache.entry.default.expire.time</literal></para></entry>
       <entry>
        <para>How many minutes to store a user data entry in the global user
        data cache</para>
       </entry>
       <entry><para>30 (minutes)</para></entry>
       <entry><para>Server &amp; SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>com.sun.identity.idm.cache.entry.expire.enabled</literal></para></entry>
       <entry>
        <para>Whether user data entries in the global user data cache should
        expire over time</para>
       </entry>
       <entry><para><literal>false</literal></para></entry>
       <entry><para>Server &amp; SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>com.sun.identity.idm.remote.notification.enabled</literal></para></entry>
       <entry>
        <para>Whether the SDK client such as a policy agent should register
        a notification listener for user data changes with the OpenAM
        server.</para>

        <para>The SDK client uses the URL specified by
        <literal>com.sun.identity.client.notification.url</literal> to register
        the listener so that OpenAM knows where to send notifications.</para>

        <para>If notifications cannot be enabled for some reason, then the SDK
        client falls back to polling for changes.</para>
       </entry>
       <entry><para><literal>true</literal></para></entry>
       <entry><para>SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>com.sun.identity.sm.cache.enabled</literal></para></entry>
       <entry>
        <para>If <literal>com.iplanet.am.sdk.caching.enabled</literal> is
        <literal>true</literal>, this property is ignored.</para>

        <para>Otherwise, set this to <literal>true</literal> to enable caching
        of configuration data. It is recommended that you always set this to
        <literal>true</literal>.</para>
       </entry>
       <entry><para><literal>false</literal></para></entry>
       <entry><para>Server &amp; SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>sun-idrepo-ldapv3-dncache-enabled</literal></para></entry>
       <entry>
        <para>Set this to <literal>true</literal> to enable DN caching
         of user data.</para>
       </entry>
       <entry><para><literal>false</literal></para></entry>
       <entry><para>Server &amp; SDK</para></entry>
      </row>

      <row>
       <entry><para><literal>sun-idrepo-ldapv3-dncache-size</literal></para></entry>
       <entry>
        <para>Sets the cache size.</para>
       </entry>
       <entry><para><literal>1500</literal></para></entry>
       <entry><para>Server &amp; SDK</para></entry>
      </row>

     </tbody>
    </tgroup>
   </table>
  </section>
 </section>
</chapter>
